<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Can Qin</title> <meta name="author" content="Can Qin"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&amp;family=IBM+Plex+Mono:wght@400;500&amp;display=swap"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://canqin001.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post about-page"> <header class="about-hero hero--underline hero--grid"> <h1 class="post-title"> <span class="hero-first-name">Can</span> <span class="hero-last-name">Qin</span> </h1> <p class="desc">Google</p> </header> <article> <div class="clearfix"> <div class="about-profile-card"> <div class="profile float-left"> <figure> <picture> <img src="/assets/img/qincan01_5.JPG?7621c15d64fe7bcc79a57ccf1d6798c3" class="img-fluid z-depth-1" width="auto" height="auto" alt="qincan01_5.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="more-info"> </div> </div> <div class="about-bio"> <p><strong>Email:</strong> <em>qin.ca[at]northeastern.edu</em></p> <p>Hello and welcome! I am working at <strong>Google CoreML</strong>, where I focus on building <strong>Multimodal</strong> and <strong>GenMedia</strong> models, working on systems that can understand and generate across text, image, video, and other modalities. Before joining Google, I was at <strong>Salesforce AI Research</strong>, contributing to multimodal and generative models. I received my <strong>Ph.D.</strong> from <strong>Northeastern University</strong> in Boston, and during my studies I interned at <strong>Adobe</strong> and <strong>Salesforce</strong>, gaining hands-on experience in real-world AI research. I am passionate about the future and want to push the boundaries of what AI can see, reason about, and create.</p> </div> </div> <section class="about-section"> <h2 class="section-title"><a href="/news/">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jan, 2026</th> <td> I have jointed the Google, working on Multimodal and GenMedia! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec, 2025</th> <td> Vlm2vec-v2 (MMEB-V2) and our MLLM token compression survery were accepted by TMLR. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct, 2025</th> <td> Holitom was accepted by NeurIPS 25. We have released the CoDA (a 1.7b coding DLLM model). </td> </tr> <tr> <th scope="row" style="width: 20%">May, 2025</th> <td> CogAlign was accepted by ACL findings and we have released BLIP-3o. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb, 2025</th> <td> We have two papers accepted by CVPR 25! Our latest paper CogAlign was released. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep, 2024</th> <td> Our Medical MLLM paper was accepted by EMNLP 24 (Main)! </td> </tr> <tr> <th scope="row" style="width: 20%">Aug, 2024</th> <td> The xGen-MM (BLIP3) and xGen-VideoSyn-1 were released to the public! We have a paper accepted by TKDE and congrats to Yizhou! I have been invited as the reviewer of Nature Communications. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul, 2024</th> <td> We have one paper accepted by ECCV 24! </td> </tr> <tr> <th scope="row" style="width: 20%">Feb, 2024</th> <td> We have one paper accepted by CVPR 24! </td> </tr> <tr> <th scope="row" style="width: 20%">Nov, 2023</th> <td> Begin my journey at Salesforce Research in Palo Alto! </td> </tr> </table> </div> </div> </section> <section class="about-section"> <h2 class="section-title"><a href="/publications/">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/agent0.png" class="preview z-depth-1 rounded" width="250px" height="auto" alt="agent0.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xia2025agent0" class="col-sm-9"> <div class="title">Agent0: Unleashing self-evolving agents from zero data via tool-integrated reasoning</div> <div class="author"> Peng Xia, Kaide Zeng, Jiaqi Liu, <em>Can Qin</em>, Fang Wu, Yiyang Zhou, Caiming Xiong, and Huaxiu Yao</div> <div class="periodical"> <em>arXiv preprint arXiv:2511.16043</em>, 2025 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Agent</span><span class="tag">Self-evolving</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2511.16043" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/aiming-lab/Agent0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/aiming-lab/Agent0" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/aiming-lab/Agent0?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/mmeb-v2.png" class="preview z-depth-1 rounded" width="250px" height="auto" alt="mmeb-v2.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="meng2025vlm2vec" class="col-sm-9"> <div class="title">Vlm2vec-v2 (MMEB-V2): Advancing multimodal embedding for videos, images, and visual documents</div> <div class="author"> Rui Meng, Ziyan Jiang, Ye Liu, Mingyi Su, Xinyi Yang, Yuepeng Fu, <em>Can Qin</em>, Zeyuan Chen, Ran Xu, Caiming Xiong, and  others</div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2025 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Embedding Model</span><span class="tag">Multimodal</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2507.04590" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/TIGER-AI-Lab/VLM2Vec" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/TIGER-AI-Lab/VLM2Vec" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/TIGER-AI-Lab/VLM2Vec?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> <a href="https://tiger-ai-lab.github.io/VLM2Vec/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/token-compression-survey.png" class="preview z-depth-1 rounded" width="250px" height="auto" alt="token-compression-survey.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="shao2025tokens" class="col-sm-9"> <div class="title">When Tokens Talk Too Much: A Survey of Multimodal Long-context Token Compression across Images, Videos, and Audios</div> <div class="author"> Kele Shao, Keda Tao, Kejia Zhang, Sicheng Feng, Mu Cai, Yuzhang Shang, Haoxuan You, <em>Can Qin</em>, Yang Sui, and Huan Wang</div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2025 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Token Compression</span><span class="tag">Survey</span><span class="tag">Multimodal</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2507.20198" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/cokeshao/Awesome-Multimodal-Token-Compression" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/cokeshao/Awesome-Multimodal-Token-Compression" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/cokeshao/Awesome-Multimodal-Token-Compression?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/image-blip3o.jpg" class="preview z-depth-1 rounded" width="250px" height="auto" alt="image-blip3o.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2025blip3" class="col-sm-9"> <div class="title">BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset</div> <div class="author"> Jiuhai Chen, Zhiyang Xu, Xichen Pan, Yushi Hu, <em>Can Qin</em>, Tom Goldstein, Lifu Huang, Tianyi Zhou, Saining Xie, Silvio Savarese, and  others</div> <div class="periodical"> <em>arXiv preprint arXiv:2505.09568</em>, 2025 </div> <div class="periodical"> </div> <div class="tags"><span class="tag">Unified Multimodal Model</span></div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2505.09568" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/JiuhaiChen/BLIP3o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/JiuhaiChen/BLIP3o" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/JiuhaiChen/BLIP3o?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/dycoke-demo.gif" class="preview z-depth-1 rounded" width="250px" height="auto" alt="dycoke-demo.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tao2024dycoke" class="col-sm-9"> <div class="title">DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models</div> <div class="author"> Keda Tao, <em>Can Qin</em>, Haoxuan You, Yang Sui, and Huan Wang</div> <div class="periodical"> <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Video LLM</span><span class="tag">Token Compression</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2411.15024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/KD-TAO/DyCoke?tab=readme-ov-file" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/KD-TAO/DyCoke?tab=readme-ov-file" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/KD-TAO/DyCoke?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/xgen-videosyn-1.gif" class="preview z-depth-1 rounded" width="250px" height="auto" alt="xgen-videosyn-1.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="qin2024xgen" class="col-sm-9"> <div class="title">xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations</div> <div class="author"> <em>Can Qin</em>, Congying Xia, Krithika Ramakrishnan, Michael Ryoo, Lifu Tu, Yihao Feng, Manli Shu, Honglu Zhou, Anas Awadalla, Jun Wang, and  others</div> <div class="periodical"> <em>arXiv preprint arXiv:2408.12590</em>, 2024 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Diffusion</span><span class="tag">Video Generation</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2408.12590" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/blip3.png" class="preview z-depth-1 rounded" width="250px" height="auto" alt="blip3.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xue2024xgen" class="col-sm-9"> <div class="title">xGen-MM (BLIP-3): A Family of Open Large Multimodal Models</div> <div class="author"> Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael S Ryoo, and  others</div> <div class="periodical"> <em>arXiv preprint arXiv:2408.08872</em>, 2024 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">VLM</span><span class="tag">Multimodal</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2408.08872" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/salesforce/LAVIS/tree/xgen-mm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/salesforce/LAVIS/tree/xgen-mm" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/salesforce/LAVIS?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/hive.png" class="preview z-depth-1 rounded" width="250px" height="auto" alt="hive.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2023hive" class="col-sm-9"> <div class="title">HIVE: Harnessing Human Feedback for Instructional Visual Editing</div> <div class="author"> Shu Zhang*, Xinyi Yang*, Yihao Feng*, <em>Can Qin</em>, Chia-Chih Chen, Ning Yu, Zeyuan Chen, Huan Wang, Silvio Savarese, Stefano Ermon, Caiming Xiong, and Ran Xu</div> <div class="periodical"> <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Diffusion</span><span class="tag">Image Editing</span><span class="tag">Human-in-the-loop</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2303.09618" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/salesforce/HIVE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/salesforce/HIVE" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/salesforce/HIVE?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <img src="/assets/img/publication_preview/unicontrol.png" class="preview z-depth-1 rounded" width="250px" height="auto" alt="unicontrol.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="qin2023unicontrol" class="col-sm-9"> <div class="title">UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild</div> <div class="author"> <em>Can Qin</em>, Shu Zhang, Ning Yu, Yihao Feng, Xinyi Yang, Yingbo Zhou, Huan Wang, Juan Carlos Niebles, Caiming Xiong, Silvio Savarese, Stefano Ermon, Yun Fu, and Ran Xu</div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="periodical"> </div> <div class="tags"> <span class="tag">Diffusion</span><span class="tag">Controllable Image Generation</span> </div> <div class="links"> <a href="http://arxiv.org/abs/arXiv:2305.11147" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/salesforce/UniControl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/salesforce/UniControl" class="github-stars-badge" aria-label="GitHub stars" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/github/stars/salesforce/UniControl?style=flat-square&amp;label=stars" alt="GitHub stars" class="github-stars-img"> </a> <a href="https://canqin001.github.io/UniControl-Page" class="btn btn-sm z-depth-0" role="button">Website</a> </div> </div> </div> </li> </ol> </div> </section> <div class="social about-social"> <div class="contact-icons"> <a href="mailto:%71%69%6E.%63%61@%6E%6F%72%74%68%65%61%73%74%65%72%6E.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=QCik-YcAAAAJ&amp;hl=en&amp;authuser=1" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/canqin001" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/can-qin-5b7b33168" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Can Qin. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>