@article{chen2025blip3,
  selected={true},
  title={BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset},
  author={Chen, Jiuhai and Xu, Zhiyang and Pan, Xichen and Hu, Yushi and Qin, Can and Goldstein, Tom and Huang, Lifu and Zhou, Tianyi and Xie, Saining and Savarese, Silvio and others},
  journal={arXiv preprint arXiv:2505.09568},
  year={2025},
  arXiv={arXiv:2505.09568},
  preview={image-blip3o.jpg},
  code={https://github.com/JiuhaiChen/BLIP3o},
}


@article{tao2025plug,
  selected={true},
  abbr={arXiv},
  title={Plug-and-Play 1. x-Bit KV Cache Quantization for Video Large Language Models},
  author={Tao, Keda and You, Haoxuan and Sui, Yang and Qin, Can and Wang, Huan},
  journal={arXiv preprint arXiv:2503.16257},
  arXiv={arXiv:2503.16257},
  year={2025},
  preview={vidkv.png},
  code={https://github.com/KD-TAO/VidKV},
  
}

@article{huang2025vision,
  selected={true},
  abbr={arXiv},
  title={Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding},
  author={Huang, Kung-Hsiang and Qin, Can and Qiu, Haoyi and Laban, Philippe and Joty, Shafiq and Xiong, Caiming and Wu, Chien-Sheng},
  journal={Annual Meeting of the Association for Computational Linguistics (ACL Findings)},
  arXiv={arXiv:2502.11492},
  year={2025},
  code={https://github.com/SalesforceAIResearch/CogAlign},
  preview={cogalign.png}
}

@article{tao2024dycoke,
  selected={true},
  abbr={CVPR},
  title={DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models},
  author={Tao, Keda and Qin, Can and You, Haoxuan and Sui, Yang and Wang, Huan},
  arXiv={arXiv:2411.15024},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025},
  preview={dycoke-demo.gif},
  code={https://github.com/KD-TAO/DyCoke?tab=readme-ov-file},
}


@article{ryoo2024xgen,
selected={true},
abbr={arXiv},
  title={xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs},
  author={Ryoo, Michael S and Zhou, Honglu and Kendre, Shrikant and Qin, Can and Xue, Le and Shu, Manli and Savarese, Silvio and Xu, Ran and Xiong, Caiming and Niebles, Juan Carlos},
  journal={arXiv preprint arXiv:2410.16267},
  year={2024},
  arXiv={arXiv:2410.16267},
  preview={xgen-mm-vid1.gif},
  website={https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html}
}

@article{qin2024xgen,
selected={true},
abbr={arXiv},
  title={xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations},
  author={Qin, Can and Xia, Congying and Ramakrishnan, Krithika and Ryoo, Michael and Tu, Lifu and Feng, Yihao and Shu, Manli and Zhou, Honglu and Awadalla, Anas and Wang, Jun and others},
  journal={arXiv preprint arXiv:2408.12590},
  year={2024},
  arXiv={arXiv:2408.12590},
  code={https://github.com/SalesforceAIResearch/xgen-videosyn},
  preview={xgen-videosyn-1.gif},
}

@article{xue2024xgen,
selected={true},
abbr={arXiv},
  title={xGen-MM (BLIP-3): A Family of Open Large Multimodal Models},
  author={Xue, Le and Shu, Manli and Awadalla, Anas and Wang, Jun and Yan, An and Purushwalkam, Senthil and Zhou, Honglu and Prabhu, Viraj and Dai, Yutong and Ryoo, Michael S and others},
  journal={arXiv preprint arXiv:2408.08872},
  year={2024},
  arXiv={arXiv:2408.08872},
  code={https://github.com/salesforce/LAVIS/tree/xgen-mm},
  preview={blip3.png}
}

@inproceedings{sun2024st,
selected={true},
abbr={EMNLP},
title={Self-Training Large Language and Vision Assistant for Medical},
author={Sun, Guohao and Qin, Can and Fu, Huazhu and Wang, Linwei and Tao, Zhiqiang},
booktitle={The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
year={2024},
arXiv={arXiv:2406.19973},
code={https://github.com/heliossun/STLLaVA-Med},
preview={preference_data_st_llava_med.png}
}


@article{sun2024sq,
 selected={true},
  abbr={ECCV},
  title={SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant},
  author={Sun, Guohao and Qin, Can and Wang, Jiamian and Chen, Zeyuan and Xu, Ran and Tao, Zhiqiang},
  journal={European Conference on Computer Vision (ECCV)},
  year={2024},
  arXiv={arXiv:2403.11299},
  code={https://github.com/heliossun/SQ-LLaVA},
  preview={sq-llava.png}
}


@article{zhang2023hive,
 selected={true},
  abbr={CVPR},
  title={HIVE: Harnessing Human Feedback for Instructional Visual Editing},
  author={Zhang*, Shu and Yang*, Xinyi and Feng*, Yihao and Qin, Can and Chen, Chia-Chih and Yu, Ning and Chen, Zeyuan and Wang, Huan and Savarese, Silvio and Ermon, Stefano and Xiong, Caiming and Xu, Ran},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024},
  arXiv={arXiv:2303.09618}, 
  code={https://github.com/salesforce/HIVE},
  preview={hive.png},
  }




@article{wang2023state,
  abbr={arXiv},
  title={Why is the state of neural network pruning so confusing? on the fairness, comparison setup, and trainability in network pruning},
  author={Wang, Huan and Qin, Can and Bai, Yue and Fu, Yun},
  journal={arXiv:2301.05219},
  year={2023},
  arxiv={arXiv:2301.05219},
  code={https://github.com/MingSun-Tse/Why-the-State-of-Pruning-So-Confusing}
}

@article{qin2023unicontrol,
  selected={true},
  abbr={NeurIPS},
  title={UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild},
  author={Qin, Can and Zhang, Shu and Yu, Ning and Feng, Yihao and Yang, Xinyi and Zhou, Yingbo and Wang, Huan and Niebles, Juan Carlos and Xiong, Caiming and Savarese, Silvio and Ermon, Stefano and Fu, Yun and Xu, Ran},
  journal={Advances in Neural Information Processing Systems (NeurIPS},
  year={2023},
  arxiv={arXiv:2305.11147},
  code={https://github.com/salesforce/UniControl},
  website={https://canqin001.github.io/UniControl-Page},
  preview={unicontrol.png},
}


@article{wang2021rethinking,
  abbr={ICDM},
  title={Rethinking Adam: A twofold exponential moving average approach},
  author={Wang, Yizhou and Kang, Yue and Qin, Can and Wang, Huan and Xu, Yi and Zhang, Yulun and Fu, Yun},
  journal={IEEE International Conference on Data Mining (ICDM)},
  year={2023},
  arXiv={arXiv:2106.11514},
  code={https://github.com/wyzjack/AdaM3},
}


@article{qin2023gluegen,
  selected={true},
  abbr={ICCV},
  title={GlueGen: Plug and Play Multi-modal Encoders for X-to-image Generation},
  author={Qin, Can and Yu, Ning and Xing, Chen and Zhang, Shu and Chen, Zeyuan and Ermon, Stefano and Fu, Yun and Xiong, Caiming and Xu, Ran},
  journal={International Conference on Computer Vision (ICCV)},
  year={2023},
  arXiv={arXiv:2303.10056},
  code={https://github.com/salesforce/GlueGen},
  website={https://canqin001.github.io/GlueGen-Page/},
  preview={gluegen.png}
}



@article{robinson2023balancing,
  abbr={TIP},
  title={Balancing biases and preserving privacy on balanced faces in the wild},
  author={Robinson, Joseph P and Qin, Can and Henon, Yann and Timoner, Samson and Fu, Yun},
  journal={IEEE Transactions on Image Processing},
  year={2023},
  publisher={IEEE},
  arxiv={arXiv:2103.09118},
  code={https://github.com/visionjo/facerec-bias-bfw}
}



@article{wang2023global,
  abbr={TPAMI},
  title={Global Aligned Structured Sparsity Learning for Efficient Image Super-Resolution},
  author={Wang, Huan and Zhang, Yulun and Qin, Can and Van Gool, Luc and Fu, Yun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE},
  pdf={https://ieeexplore.ieee.org/document/10106130},
  code={}
}


@inproceedings{vs2023mask,
  abbr={CVPR},
  title={Mask-free OVIS: Open-Vocabulary Instance Segmentation without Manual Mask Annotations},
  author={VS, Vibashan and Yu, Ning and Xing, Chen and Qin, Can and Gao, Mingfei and Niebles, Juan Carlos and Patel, Vishal M and Xu, Ran},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={23539--23549},
  year={2023},
  pdf={https://openaccess.thecvf.com/content/CVPR2023/papers/VS_Mask-Free_OVIS_Open-Vocabulary_Instance_Segmentation_Without_Manual_Mask_Annotations_CVPR_2023_paper.pdf},
  code={https://github.com/Vibashan/Mask-free-OVIS},
}


@inproceedings{ma2022image,
  abbr={ICLR Oral},
  title={Image as Set of Points},
  author={Ma, Xu and Zhou, Yuqian and Wang, Huan and Qin, Can and Sun, Bin and Liu, Chang and Fu, Yun},
  booktitle={The Eleventh International Conference on Learning Representations (ICLR)},
  year={2023},
  arXiv={arXiv:2303.01494},
  code={https://github.com/ma-xu/Context-Cluster}
}


@article{ma2022close,
  abbr={arXiv},
  title={A Close Look at Spatial Modeling: From Attention to Convolution},
  author={Ma, Xu and Wang, Huan and Qin, Can and Li, Kunpeng and Zhao, Xingchen and Fu, Jie and Fu, Yun},
  journal={arXiv preprint arXiv:2212.12552},
  year={2022},
  arxiv={arXiv:2212.12552},
  code={https://github.com/ma-xu/FCViT}
}

@inproceedings{wang2022making,
  abbr={ICDM},
  title={Making Reconstruction-based Method Great Again for Video Anomaly Detection},
  author={Wang, Yizhou and Qin, Can and Bai, Yue and Xu, Yi and Ma, Xu and Fu, Yun},
  booktitle={2022 IEEE International Conference on Data Mining (ICDM)},
  pages={1215--1220},
  year={2022},
  organization={IEEE},
  arXiv={arXiv:2301.12048},
  code={https://github.com/wyzjack/MRMGA4VAD}
}

@article{qin2022semi,
  abbr={TIP},
  title={Semi-Supervised Domain Adaptive Structure Learning},
  author={Qin, Can and Wang, Lichen and Ma, Qianqian and Yin, Yu and Wang, Huan and Fu, Yun},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={7179--7190},
  year={2022},
  publisher={IEEE},
  arXiv={arXiv:2112.06161},
  code={https://github.com/canqin001/ASDA}
}


@inproceedings{qin2022external,
  abbr={KDD},
  title={External Knowledge Infusion for Tabular Pre-training Models with Dual-adapters},
  author={Qin, Can and Kim, Sungchul and Zhao, Handong and Yu, Tong and Rossi, Ryan A and Fu, Yun},
  booktitle={ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)},
  pages={1401--1409},
  year={2022},
  pdf={https://dl.acm.org/doi/abs/10.1145/3534678.3539403},
  code={}
}


@inproceedings{ma2021rethinking,
  abbr={ICLR},
  title={Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework},
  author={Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  url={https://openreview.net/pdf?id=3Pbra-_u76D},
  code={https://github.com/ma-xu/pointMLP-pytorch}
}


@inproceedings{zhang2022learning,
abbr={ICLR},
title={Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning},
author={Yulun Zhang* and Huan Wang* and Can Qin and Yun Fu},
booktitle={International Conference on Learning Representations (ICLR)},
year={2022},
pdf={https://openreview.net/pdf?id=AjGC97Aofee},
url={https://openreview.net/forum?id=AjGC97Aofee},
code={https://github.com/MingSun-Tse/SRP}
}

@article{deng2022self,
  abbr={Nature Comm},
  title={Self-directed online machine learning for topology optimization},
  author={Deng, Changyu and Wang, Yizhou and Qin, Can and Fu, Yun and Lu, Wei},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={388},
  year={2022},
  publisher={Nature Publishing Group UK London},
  url={https://www.nature.com/articles/s41467-021-27713-7},
  code={https://github.com/deng-cy/deep_learning_topology_opt}
}

@inproceedings{robinson20215th,
  abbr={FG},
  title={The 5th recognizing families in the wild data challenge: Predicting kinship from faces},
  author={Robinson, Joseph P and Qin, Can and Shao, Ming and Turk, Matthew A and Chellappa, Rama and Fu, Yun},
  booktitle={IEEE International Conference on Automatic Face and Gesture Recognition (FG)},
  pages={01--07},
  year={2021},
  organization={IEEE},
  arxiv={arXiv:2111.00598}
}

@article{qin2021slow,
  abbr={NeurIPS},
  title={Slow learning and fast inference: Efficient graph similarity computation via knowledge distillation},
  author={Qin, Can and Zhao, Handong and Wang, Lichen and Wang, Huan and Zhang, Yulun and Fu, Yun},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={14110--14121},
  year={2021},
  pdf={https://papers.nips.cc/paper/2021/file/75fc093c0ee742f6dddaa13fff98f104-Paper.pdf},
  code={https://github.com/canqin001/Efficient_Graph_Similarity_Computation}
}

@article{zhang2021aligned,
  abbr={NeurIPS Spotlight},
  title={Aligned structured sparsity learning for efficient image super-resolution},
  author={Zhang*, Yulun and Wang*, Huan and Qin, Can and Fu, Yun},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={2695--2706},
  year={2021},
  pdf={https://papers.nips.cc/paper/2021/file/15de21c670ae7c3f6f3f1f37029303c9-Paper.pdf},
  code={https://github.com/MingSun-Tse/ASSL}
}

@inproceedings{zhang2021context,
  abbr={ICCV},
  title={Context reasoning attention network for image super-resolution},
  author={Zhang, Yulun and Wei, Donglai and Qin, Can and Wang, Huan and Pfister, Hanspeter and Fu, Yun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={4278--4287},
  year={2021},
  pdf={https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Context_Reasoning_Attention_Network_for_Image_Super-Resolution_ICCV_2021_paper.pdf}
}

@inproceedings{qin2021contradictory,
  abbr={SDM},
  title={Contradictory structure learning for semi-supervised domain adaptation},
  author={Qin, Can and Wang, Lichen and Ma, Qianqian and Yin, Yu and Wang, Huan and Fu, Yun},
  booktitle={SIAM International Conference on Data Mining (SDM)},
  pages={576--584},
  year={2021},
  organization={SIAM},
  arXiv={arXiv:2002.02545},
  code={https://github.com/canqin001/Contradictory-Structure-Learning-for-Semi-supervised-Domain-Adaptation}
}

@article{wang2020neural,
  abbr={ICLR},
  title={Neural pruning via growing regularization},
  author={Wang, Huan and Qin, Can and Zhang, Yulun and Fu, Yun},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021},
  arXiv={arXiv:2012.09243},
  code={https://github.com/MingSun-Tse/Regularization-Pruning}
}



@inproceedings{robinson2020face,
  abbr={CVPRW},
  title={Face recognition: too bias, or not too bias?},
  author={Robinson, Joseph P and Livitz, Gennady and Henon, Yann and Qin, Can and Fu, Yun and Timoner, Samson},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--1},
  year={2020},
  pdf={https://openaccess.thecvf.com/content_CVPRW_2020/papers/w1/Robinson_Face_Recognition_Too_Bias_or_Not_Too_Bias_CVPRW_2020_paper.pdf},
  code={https://github.com/visionjo/facerec-bias-bfw}
}

@inproceedings{liu2020generative,
  abbr={ECCV},
  title={Generative view-correlation adaptation for semi-supervised multi-view learning},
  author={Liu, Yunyu and Wang, Lichen and Bai, Yue and Qin, Can and Ding, Zhengming and Fu, Yun},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={318--334},
  year={2020},
  organization={Springer},
  pdf={http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590307.pdf},
  code={https://github.com/wenwen0319/GVCA}
}

@inproceedings{wang2020dual,
  abbr={AAAI},
  title={Dual relation semi-supervised multi-label learning},
  author={Wang, Lichen and Liu, Yunyu and Qin, Can and Sun, Gan and Fu, Yun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  volume={34},
  number={04},
  pages={6227--6234},
  year={2020},
  pdf={https://ojs.aaai.org/index.php/AAAI/article/view/6089}
}

@article{wu2020semi,
  abbr={Remote Sensing},
  title={Semi-supervised hyperspectral image classification via spatial-regulated self-training},
  author={Wu, Yue and Mu, Guifeng and Qin, Can and Miao, Qiguang and Ma, Wenping and Zhang, Xiangrong},
  journal={Remote Sensing},
  volume={12},
  number={1},
  pages={159},
  year={2020},
  pdf={https://pdfs.semanticscholar.org/f140/30d2d21742d26dda27462f7bf819dc88a41a.pdf}
}

@article{qin2019pointdan,
  abbr={NeurIPS},
  title={Pointdan: A multi-scale 3d domain adaption network for point cloud representation},
  author={Qin*, Can and You*, Haoxuan and Wang, Lichen and Kuo, C-C Jay and Fu, Yun},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={32},
  year={2019},
  pdf={http://papers.nips.cc/paper/8940-pointdan-a-multi-scale-3d-domain-adaption-network-for-point-cloud-representation.pdf},
  code={https://github.com/canqin001/PointDAN}
}


@inproceedings{qin2019generatively,
  abbr={ICCVW},
  title={Generatively inferential co-training for unsupervised domain adaptation},
  author={Qin, Can and Wang, Lichen and Zhang, Yulun and Fu, Yun},
  booktitle={IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019},
  pdf={http://openaccess.thecvf.com/content_ICCVW_2019/papers/RLQ/Qin_Generatively_Inferential_Co-Training_for_Unsupervised_Domain_Adaptation_ICCVW_2019_paper.pdf},
  code={}
}